{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEmbIu3VZ0KF"
      },
      "source": [
        "# Agglomerative Clustering\n",
        "### Data\n",
        "* https://video.ittensive.com/machine-learning/hacktherealty/exposition_train.basic.csv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKWUgpUpAJrv"
      },
      "source": [
        "### Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMMIDKFYAJGG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGHW8ZGZ0KL"
      },
      "source": [
        "### Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4Kr7aHsZ0KM",
        "outputId": "ffc8ec6c-e309-49df-83cd-45ea9d1daa62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_area</th>\n",
              "      <th>ceiling_height</th>\n",
              "      <th>rooms</th>\n",
              "      <th>living_area</th>\n",
              "      <th>price</th>\n",
              "      <th>day_mean</th>\n",
              "      <th>doy_108</th>\n",
              "      <th>price_locality_name_median</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>105.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>95000</td>\n",
              "      <td>2.456912</td>\n",
              "      <td>0</td>\n",
              "      <td>2.261905</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1</td>\n",
              "      <td>19.200001</td>\n",
              "      <td>25000</td>\n",
              "      <td>3.028689</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37.599998</td>\n",
              "      <td>2.64</td>\n",
              "      <td>0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>26000</td>\n",
              "      <td>3.091993</td>\n",
              "      <td>0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>35000</td>\n",
              "      <td>3.101010</td>\n",
              "      <td>0</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>80000</td>\n",
              "      <td>2.495468</td>\n",
              "      <td>0</td>\n",
              "      <td>1.904762</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_area  ceiling_height  rooms  living_area  price  day_mean  doy_108  \\\n",
              "0  105.000000            3.00      3    50.000000  95000  2.456912        0   \n",
              "1   40.000000            3.00      1    19.200001  25000  3.028689        0   \n",
              "2   37.599998            2.64      0    19.000000  26000  3.091993        0   \n",
              "3   80.000000            3.00      3    49.000000  35000  3.101010        0   \n",
              "4  100.000000            3.00      3    49.000000  80000  2.495468        0   \n",
              "\n",
              "   price_locality_name_median  target  \n",
              "0                    2.261905       1  \n",
              "1                    1.000000       2  \n",
              "2                    0.619048       2  \n",
              "3                    1.250000       2  \n",
              "4                    1.904762       3  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = pd.read_csv('https://video.ittensive.com/machine-learning/hacktherealty/exposition_train.basic.csv.gz')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Sn-zLAZ0KM"
      },
      "source": [
        "### Sample Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfFVHqLkZ0KN"
      },
      "outputs": [],
      "source": [
        "(train, test) = train_test_split(train_data, test_size=0.2)\n",
        "train = pd.DataFrame(train)\n",
        "test = pd.DataFrame(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw54PR5GZ0KN"
      },
      "source": [
        "### Agglomerative Clustering\n",
        "Nearest points by distance are combined\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIZLcNCBZ0KO"
      },
      "outputs": [],
      "source": [
        "clusters_total = 100\n",
        "aglo = AgglomerativeClustering(n_clusters=clusters_total, linkage=\"single\")\n",
        "# for constructing a dendrogram\n",
        "# aglo = AgglomerativeClustering(n_clusters=None, distance_threshold=0, linkage=\"single\")\n",
        "train[\"target_cluster\"] = aglo.fit_predict(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAHNRhBEZ0KO"
      },
      "outputs": [],
      "source": [
        "def plot_dendrogram(model, **kwargs):\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXDmkfVGZ0KP"
      },
      "outputs": [],
      "source": [
        "#plt.title('Hierarchical Dendrogram')\n",
        "#plot_dendrogram(aglo)\n",
        "#plt.xlabel(\"Number of data objects\")\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzaHdkCeZ0KP"
      },
      "source": [
        "Calculate the \"purity\" of clustering: how popular is the most popular class in each cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apaI0gJAZ0KP",
        "outputId": "71518f3c-5266-459e-cc44-fb9a03913fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "((0, 1), 4)\n",
            "((0, 3), 2)\n",
            "((0, 4), 1)\n",
            "((0, 5), 7)\n",
            "((1, 1), 4)\n",
            "((1, 2), 1)\n",
            "((1, 3), 12)\n",
            "((1, 4), 15)\n",
            "((1, 5), 36)\n",
            "((2, 5), 2)\n",
            "((3, 1), 1)\n",
            "((3, 3), 2)\n",
            "((3, 4), 3)\n",
            "((3, 5), 6)\n",
            "((4, 1), 6)\n",
            "((4, 2), 8)\n",
            "((4, 3), 19)\n",
            "((4, 4), 29)\n",
            "((4, 5), 111)\n",
            "((5, 3), 1)\n",
            "((5, 5), 2)\n",
            "((6, 1), 1)\n",
            "((6, 4), 2)\n",
            "((6, 5), 2)\n",
            "((7, 1), 58005)\n",
            "((7, 2), 64721)\n",
            "((7, 3), 61979)\n",
            "((7, 4), 39862)\n",
            "((7, 5), 59833)\n",
            "((8, 1), 3)\n",
            "((8, 2), 1)\n",
            "((8, 3), 6)\n",
            "((8, 4), 1)\n",
            "((8, 5), 13)\n",
            "((9, 2), 1)\n",
            "((9, 3), 1)\n",
            "((9, 4), 1)\n",
            "((9, 5), 14)\n",
            "((10, 2), 1)\n",
            "((10, 4), 1)\n",
            "((10, 5), 8)\n",
            "((11, 1), 1)\n",
            "((11, 2), 1)\n",
            "((11, 4), 1)\n",
            "((11, 5), 2)\n",
            "((12, 1), 1)\n",
            "((12, 2), 1)\n",
            "((12, 3), 1)\n",
            "((12, 5), 10)\n",
            "((13, 3), 1)\n",
            "((13, 5), 4)\n",
            "((14, 2), 1)\n",
            "((14, 5), 1)\n",
            "((15, 5), 3)\n",
            "((16, 2), 3)\n",
            "((16, 3), 1)\n",
            "((16, 4), 1)\n",
            "((16, 5), 10)\n",
            "((17, 1), 3)\n",
            "((17, 3), 10)\n",
            "((17, 4), 6)\n",
            "((17, 5), 13)\n",
            "((18, 1), 4)\n",
            "((18, 2), 5)\n",
            "((18, 3), 9)\n",
            "((18, 4), 12)\n",
            "((18, 5), 61)\n",
            "((19, 2), 1)\n",
            "((19, 3), 2)\n",
            "((19, 4), 1)\n",
            "((19, 5), 1)\n",
            "((20, 1), 2)\n",
            "((20, 2), 3)\n",
            "((20, 3), 5)\n",
            "((20, 4), 4)\n",
            "((20, 5), 25)\n",
            "((21, 2), 1)\n",
            "((21, 4), 1)\n",
            "((21, 5), 7)\n",
            "((22, 1), 5)\n",
            "((22, 2), 3)\n",
            "((22, 3), 12)\n",
            "((22, 4), 20)\n",
            "((22, 5), 76)\n",
            "((23, 2), 2)\n",
            "((24, 1), 1)\n",
            "((25, 3), 1)\n",
            "((26, 5), 4)\n",
            "((27, 5), 2)\n",
            "((28, 3), 1)\n",
            "((28, 5), 1)\n",
            "((29, 5), 1)\n",
            "((30, 2), 1)\n",
            "((30, 3), 1)\n",
            "((30, 4), 1)\n",
            "((30, 5), 2)\n",
            "((31, 1), 2)\n",
            "((32, 5), 2)\n",
            "((33, 5), 2)\n",
            "((34, 4), 1)\n",
            "((35, 5), 4)\n",
            "((36, 1), 1)\n",
            "((36, 2), 1)\n",
            "((37, 5), 1)\n",
            "((38, 3), 1)\n",
            "((39, 1), 1)\n",
            "((40, 1), 1)\n",
            "((40, 3), 1)\n",
            "((40, 4), 1)\n",
            "((40, 5), 5)\n",
            "((41, 2), 1)\n",
            "((42, 1), 1)\n",
            "((42, 4), 1)\n",
            "((42, 5), 1)\n",
            "((43, 4), 1)\n",
            "((43, 5), 1)\n",
            "((44, 2), 2)\n",
            "((45, 3), 1)\n",
            "((45, 4), 1)\n",
            "((46, 4), 1)\n",
            "((46, 5), 4)\n",
            "((47, 3), 1)\n",
            "((48, 2), 1)\n",
            "((48, 5), 1)\n",
            "((49, 5), 1)\n",
            "((50, 3), 1)\n",
            "((51, 3), 1)\n",
            "((52, 2), 1)\n",
            "((53, 5), 1)\n",
            "((54, 3), 1)\n",
            "((54, 4), 4)\n",
            "((54, 5), 3)\n",
            "((55, 1), 1)\n",
            "((56, 3), 1)\n",
            "((57, 5), 1)\n",
            "((58, 5), 1)\n",
            "((59, 5), 1)\n",
            "((60, 5), 1)\n",
            "((61, 5), 1)\n",
            "((62, 1), 1)\n",
            "((63, 1), 1)\n",
            "((64, 3), 1)\n",
            "((65, 5), 1)\n",
            "((66, 1), 1)\n",
            "((66, 3), 1)\n",
            "((66, 4), 3)\n",
            "((66, 5), 1)\n",
            "((67, 3), 1)\n",
            "((68, 2), 1)\n",
            "((68, 5), 1)\n",
            "((69, 5), 1)\n",
            "((70, 1), 1)\n",
            "((71, 2), 1)\n",
            "((72, 4), 1)\n",
            "((73, 1), 1)\n",
            "((74, 1), 1)\n",
            "((74, 2), 1)\n",
            "((74, 4), 1)\n",
            "((75, 5), 1)\n",
            "((76, 1), 1)\n",
            "((77, 3), 1)\n",
            "((78, 5), 1)\n",
            "((79, 2), 1)\n",
            "((80, 5), 1)\n",
            "((81, 1), 1)\n",
            "((82, 1), 1)\n",
            "((82, 3), 1)\n",
            "((82, 4), 1)\n",
            "((82, 5), 1)\n",
            "((83, 4), 1)\n",
            "((84, 2), 1)\n",
            "((85, 2), 1)\n",
            "((86, 2), 1)\n",
            "((86, 3), 1)\n",
            "((87, 5), 1)\n",
            "((88, 4), 1)\n",
            "((89, 2), 1)\n",
            "((90, 5), 1)\n",
            "((91, 5), 1)\n",
            "((92, 5), 1)\n",
            "((93, 1), 1)\n",
            "((94, 5), 1)\n",
            "((95, 3), 1)\n",
            "((96, 4), 1)\n",
            "((97, 2), 1)\n",
            "((98, 2), 1)\n",
            "((98, 4), 2)\n",
            "((98, 5), 5)\n",
            "((99, 5), 1)\n",
            "Чистота:  0.8318358293589213\n"
          ]
        }
      ],
      "source": [
        "groups = train.groupby([\"target_cluster\",\"target\"]).count()[\"total_area\"]\n",
        "clusters_items = [0]*clusters_total\n",
        "clusters_popular = [0]*clusters_total\n",
        "clusters_class = [0]*clusters_total\n",
        "for group in groups.iteritems():\n",
        "    print (group)\n",
        "    items = group[1]\n",
        "    cluster = group[0][0]\n",
        "    clusters_items[cluster] += items\n",
        "    if items > clusters_popular[cluster]:\n",
        "        clusters_popular[cluster] = items\n",
        "        clusters_class[cluster] = group[0][1]\n",
        "purity = 0\n",
        "for i in range(0, clusters_total):\n",
        "    purity += clusters_popular[i] / clusters_items[i] / clusters_total\n",
        "print (\"Purity: \", purity) # 0.83"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}